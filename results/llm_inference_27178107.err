/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes


  warn(msg)
/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: /scratch/cs529314/micromamba/envs/e2e_env did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: /opt/oscer/software/flex/2.6.4/lib:/opt/oscer/software/binutils/2.38/lib did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
Traceback (most recent call last):
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1778, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/integrations/bitsandbytes.py", line 21, in <module>
    import bitsandbytes as bnb
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/__init__.py", line 6, in <module>
    from . import cuda_setup, utils, research
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/research/__init__.py", line 1, in <module>
    from . import nn
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
    from .modules import LinearFP8Mixed, LinearFP8Global
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
    from bitsandbytes.optim import GlobalOptimManager
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/optim/__init__.py", line 6, in <module>
    from bitsandbytes.cextension import COMPILED_WITH_CUDA
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/bitsandbytes/cextension.py", line 20, in <module>
    raise RuntimeError('''
RuntimeError: 
        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "llm_inference.py", line 102, in <module>
    main()
  File "llm_inference.py", line 97, in main
    bot = E2ETuneBot(model_name)
  File "llm_inference.py", line 31, in __init__
    self.pipeline = transformers.pipeline(
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/pipelines/__init__.py", line 926, in pipeline
    framework, model = infer_framework_load_model(
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/pipelines/base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3657, in from_pretrained
    hf_quantizer.validate_environment(
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/quantizers/quantizer_bnb_4bit.py", line 78, in validate_environment
    from ..integrations import validate_bnb_backend_availability
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1766, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/scratch/cs529314/micromamba/envs/e2e_env/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1780, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):

        CUDA Setup failed despite GPU being available. Please run the following command to get more information:

        python -m bitsandbytes

        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
